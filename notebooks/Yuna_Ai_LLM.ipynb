{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Welcome to Yuna Ai LLM trainer"
      ],
      "metadata": {
        "id": "jJy_iUhoZJQw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Kncicf0oOVl"
      },
      "outputs": [],
      "source": [
        "!pip install unsloth \"xformers==0.0.28.post2\"\n",
        "!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "# !pip install -U peft transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize trainer with paths and hyperparameters (adjust paths as needed)"
      ],
      "metadata": {
        "id": "PO8W1X7naZN4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eSvM9zX_2d3"
      },
      "outputs": [],
      "source": [
        "from aiflow.trainer import YunaLLMTrainer\n",
        "trainer = YunaLLMTrainer(\n",
        "    model_path=\"yukiarimo/yuna-ai-v4\",\n",
        "    dataset_file=\"data.jsonl\",\n",
        "    output_dir=\"newmodel-output\",\n",
        "    max_seq_length=16384,\n",
        "    load_in_4bit=True,\n",
        "    device_map={\"\": 0}\n",
        ")\n",
        "\n",
        "# Create model and tokenizer\n",
        "trainer.create_model(dtype=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup LoRA configuration"
      ],
      "metadata": {
        "id": "Sgz-KTv3adqp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmUBVEnvCDJv"
      },
      "outputs": [],
      "source": [
        "trainer.setup_lora(\n",
        "    r=128,\n",
        "    lora_alpha=128,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                    \"gate_proj\", \"up_proj\", \"down_proj\",\n",
        "                    \"embed_tokens\", \"lm_head\"],\n",
        "    lora_dropout=0.01,\n",
        "    bias=\"all\",\n",
        "    use_gradient_checkpointing=\"unsloth\",\n",
        "    random_state=42,\n",
        "    use_rslora=True,\n",
        "    loftq_config=None\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model using UnslothTrainer wrapper"
      ],
      "metadata": {
        "id": "MOCqvKNsa2v3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95_Nn-89DhsL"
      },
      "outputs": [],
      "source": [
        "print(\"Starting training...\")\n",
        "trainer_stats = trainer.train_model(training_args_kwargs={\n",
        "    \"output_dir\": \"outputs-pack3\",\n",
        "    \"per_device_train_batch_size\": 1,\n",
        "    \"gradient_accumulation_steps\": 2,\n",
        "    \"max_steps\": 300,\n",
        "    \"warmup_steps\": 20,\n",
        "    \"warmup_ratio\": 0.1,\n",
        "    \"learning_rate\": 1e-6,\n",
        "    \"embedding_learning_rate\": 1e-7,\n",
        "    \"bf16\": True,\n",
        "    \"logging_steps\": 1,\n",
        "    \"optim\": \"adamw_hf\",\n",
        "    \"weight_decay\": 0.01,\n",
        "    \"lr_scheduler_type\": \"constant\",\n",
        "    \"seed\": 42,\n",
        "    \"max_grad_norm\": 1.0,\n",
        "    \"group_by_length\": True,\n",
        "    \"report_to\": \"tensorboard\",\n",
        "    \"save_steps\": 10,\n",
        "    \"gradient_checkpointing\": True,\n",
        "})\n",
        "print(\"Trainer stats:\", trainer_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge LoRA weights into the base model and save the merged model and tokenizer"
      ],
      "metadata": {
        "id": "3adTid7VaRYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_model_dir = trainer.merge_and_save_model(\n",
        "    merged_model_dir=\"model-merged\",\n",
        "    checkpoint_dir=\"checkpoint-20\"\n",
        ")\n",
        "print(\"Merged model saved to:\", merged_model_dir)"
      ],
      "metadata": {
        "id": "wpvveZO4aSAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload model to Hugging Face repository"
      ],
      "metadata": {
        "id": "-DyWbyHudKhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.huggingface_upload(repo=\"yukiarimo/yuna-ai-v4-atomic-trained\", model_dir=\"newmodel-outputs\"):"
      ],
      "metadata": {
        "id": "aIgmdRf5RgDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference setup: load a model checkpoint for inference"
      ],
      "metadata": {
        "id": "KAytDyEXZ6AD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZP7SZQIt2XH2"
      },
      "outputs": [],
      "source": [
        "trainer.inference_setup(\n",
        "    inference_model_path=\"/content/himitsu-extra-outputsырше/checkpoint-14\",\n",
        "    max_seq_length=2048,\n",
        "    dtype=None\n",
        ")\n",
        "generated = trainer.generate_text(\n",
        "    text=\"<dialog>\\n<yuki>How are you?</yuki>\\n<yuna>\"\n",
        ")\n",
        "print(\"Generated text:\\n\", generated)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create and save new model with updated configuration and additional tokens"
      ],
      "metadata": {
        "id": "tGyRd0t8ZtJ4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nA-MclXtjRm"
      },
      "outputs": [],
      "source": [
        "additional_tokens = [\"<memory>\", \"</memory>\", \"<shujinko>\", \"</shujinko>\",\n",
        "                        \"<kanojo>\", \"</kanojo>\", \"<dialog>\", \"<yuki>\", \"</yuki>\",\n",
        "                        \"<yuna>\", \"</yuna>\", \"<hito>\", \"</hito>\", \"<qt>\", \"</qt>\",\n",
        "                        \"<action>\", \"</action>\", \"<data>\", \"</data>\", \"<unk>\"]\n",
        "new_model_dir = trainer.create_and_save_new_model(\n",
        "    base_model_name=\"yukiarimo/yuna-ai-v3\",\n",
        "    new_model_dir=\"yukiarimo/yuna-ai-v4-base\",\n",
        "    temperature=0.7,\n",
        "    additional_tokens=additional_tokens\n",
        ")\n",
        "print(\"New model created and saved to:\", new_model_dir)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}